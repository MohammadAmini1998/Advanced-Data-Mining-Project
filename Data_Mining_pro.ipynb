{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UskWUThoYw8",
        "outputId": "375c901e-5bb6-4b3c-80cc-2682ab436751"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "p7zip-full is already the newest version (16.02+dfsg-7build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 15 not upgraded.\n",
            "Collecting py7zr\n",
            "  Downloading py7zr-0.20.5-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting texttable (from py7zr)\n",
            "  Downloading texttable-1.6.7-py2.py3-none-any.whl (10 kB)\n",
            "Collecting pycryptodomex>=3.6.6 (from py7zr)\n",
            "  Downloading pycryptodomex-3.18.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyzstd>=0.14.4 (from py7zr)\n",
            "  Downloading pyzstd-0.15.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (412 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.3/412.3 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyppmd<1.1.0,>=0.18.1 (from py7zr)\n",
            "  Downloading pyppmd-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.8/138.8 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pybcj>=0.6.0 (from py7zr)\n",
            "  Downloading pybcj-1.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.8/49.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multivolumefile>=0.2.3 (from py7zr)\n",
            "  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
            "Collecting brotli>=1.0.9 (from py7zr)\n",
            "  Downloading Brotli-1.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting inflate64>=0.3.1 (from py7zr)\n",
            "  Downloading inflate64-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from py7zr) (5.9.5)\n",
            "Installing collected packages: texttable, brotli, pyzstd, pyppmd, pycryptodomex, pybcj, multivolumefile, inflate64, py7zr\n",
            "Successfully installed brotli-1.0.9 inflate64-0.3.1 multivolumefile-0.2.3 py7zr-0.20.5 pybcj-1.0.1 pycryptodomex-3.18.0 pyppmd-1.0.0 pyzstd-0.15.9 texttable-1.6.7\n"
          ]
        }
      ],
      "source": [
        " # Installing google colab and p7zip. p7zip is for unziping files in google colab.\n",
        " !pip install -q kaggle\n",
        " !apt-get install p7zip-full\n",
        " !pip install py7zr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tysizWOqbrZL"
      },
      "outputs": [],
      "source": [
        "#Importing necessary libriareis like pandas and nupy\n",
        "import pandas as pd\n",
        "import py7zr\n",
        "import os\n",
        "import numpy as np\n",
        "import shutil\n",
        "import torch\n",
        "import statistics\n",
        "from random import sample\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import warnings\n",
        "import statistics\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fBdnklobqeyi"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jwgSOqF3qgU6"
      },
      "outputs": [],
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gUrQN5_jqkrZ"
      },
      "outputs": [],
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sVG6CX5LkS3e"
      },
      "outputs": [],
      "source": [
        "\n",
        "!mv kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QAW5wHUkXpE",
        "outputId": "05dafc8f-3b0b-47c1-eea9-25c962717690"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading cifar-10.zip to /content\n",
            " 97% 697M/715M [00:06<00:00, 124MB/s]\n",
            "100% 715M/715M [00:06<00:00, 118MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions download -c cifar-10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Q7ujIvA96RN",
        "outputId": "d1cfe2ac-aa03-48b0-a763-fecaf4be0785"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/cifar-10.zip\n",
            "  inflating: sampleSubmission.csv    \n",
            "  inflating: test.7z                 \n",
            "  inflating: train.7z                \n",
            "  inflating: trainLabels.csv         \n"
          ]
        }
      ],
      "source": [
        "! unzip /content/cifar-10.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5DAnFk3sic8_"
      },
      "outputs": [],
      "source": [
        "\n",
        "with py7zr.SevenZipFile('/content/train.7z', mode='r') as z:\n",
        "    z.extractall()\n",
        "\n",
        "# with py7zr.SevenZipFile('/content/test.7z', mode='r') as z:\n",
        "#     z.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "oX-yRR9_b5eO"
      },
      "outputs": [],
      "source": [
        "labels=pd.read_csv(\"/content/trainLabels.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "jXP9k-hxcOM9",
        "outputId": "ab0831fc-8e20-4202-8e0b-2f06b5f1dca8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          id       label\n",
              "0          1        frog\n",
              "1          2       truck\n",
              "2          3       truck\n",
              "3          4        deer\n",
              "4          5  automobile\n",
              "...      ...         ...\n",
              "49995  49996        bird\n",
              "49996  49997        frog\n",
              "49997  49998       truck\n",
              "49998  49999  automobile\n",
              "49999  50000  automobile\n",
              "\n",
              "[50000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-c9844a94-0dc5-46c1-8d14-420e87d6356e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>frog</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>truck</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>truck</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>deer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>automobile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>49996</td>\n",
              "      <td>bird</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>49997</td>\n",
              "      <td>frog</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>49998</td>\n",
              "      <td>truck</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>49999</td>\n",
              "      <td>automobile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>50000</td>\n",
              "      <td>automobile</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c9844a94-0dc5-46c1-8d14-420e87d6356e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-4d0262c9-f33c-420a-9cc8-160203871bd9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4d0262c9-f33c-420a-9cc8-160203871bd9')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-4d0262c9-f33c-420a-9cc8-160203871bd9 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c9844a94-0dc5-46c1-8d14-420e87d6356e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c9844a94-0dc5-46c1-8d14-420e87d6356e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gicG9k4BcYm0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f444dc94-d023-4fcd-861b-ae3847200555"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['frog' 'truck' 'deer' 'automobile' 'bird' 'horse' 'ship' 'cat' 'dog'\n",
            " 'airplane']\n"
          ]
        }
      ],
      "source": [
        "unique_classes = labels['label'].unique()\n",
        "\n",
        "# Print the unique classes\n",
        "print(unique_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4IsTH_Mvdr3K"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create the folders\n",
        "for folder_name in unique_classes:\n",
        "    folder_path = os.path.join('/content/dataset/train', folder_name)\n",
        "    os.makedirs(folder_path, exist_ok=True)\n",
        "    folder_path = os.path.join('/content/dataset/valid', folder_name)\n",
        "    os.makedirs(folder_path, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "JQ1E-RnhewP_"
      },
      "outputs": [],
      "source": [
        "\n",
        "dataset_dir = '/content/train'\n",
        "parent_dir='/content/dataset/train'\n",
        "\n",
        "\n",
        "#Loop through the DataFrame and move each image to the corresponding class folder\n",
        "for pic in os.listdir(dataset_dir):\n",
        "    id=name_without_extension = pic[:-4]\n",
        "    label = labels[labels['id'] == int(id)]\n",
        "    label=label = label['label'].values[0]\n",
        "    destination=os.path.join(parent_dir,label)\n",
        "    src=os.path.join(dataset_dir,pic)\n",
        "    shutil.move(src,destination)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "r38dWSfqcRsc"
      },
      "outputs": [],
      "source": [
        "train_dir='/content/dataset/train'\n",
        "valid_dir='/content/dataset/valid'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "pCN2Ce1Ltimy"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "use_gpu = torch.cuda.is_available()\n",
        "np.random.seed(1234)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuhYLyPLcCTB",
        "outputId": "ec831bab-36a1-46ed-ab53-06026de28324"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "250\n",
            "250\n",
            "250\n",
            "250\n",
            "250\n",
            "250\n",
            "250\n",
            "250\n",
            "250\n",
            "250\n"
          ]
        }
      ],
      "source": [
        "for label in os.listdir(train_dir):\n",
        "  len_class=len(os.listdir(os.path.join(train_dir,label)))\n",
        "  number_of_valid=round(.05*len_class)\n",
        "  print(number_of_valid)\n",
        "  valid_data_per_class=sample(os.listdir(os.path.join(train_dir,label)), k=number_of_valid)\n",
        "  for pic in valid_data_per_class:\n",
        "      src=os.path.join(train_dir,label,pic)\n",
        "      destination=os.path.join(valid_dir,label)\n",
        "      shutil.move(src,destination)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "XW_oIqqhtot5"
      },
      "outputs": [],
      "source": [
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "sz = 224\n",
        "batch_size = 32\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "2XRpWyPYw4lo"
      },
      "outputs": [],
      "source": [
        "tfms = transforms.Compose([\n",
        "    transforms.Resize((sz//2, sz//2)),  # Resize the images to half the size\n",
        "    transforms.ToTensor(),        # Tensor\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "fq--RxONvAIa"
      },
      "outputs": [],
      "source": [
        "train_ds = datasets.ImageFolder(train_dir,tfms)\n",
        "valid_ds = datasets.ImageFolder(valid_dir,tfms)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "u_zZc3NzxNTx"
      },
      "outputs": [],
      "source": [
        "train_dl = torch.utils.data.DataLoader(train_ds,\n",
        "                                       batch_size=batch_size,\n",
        "                                       shuffle=True,\n",
        "                                       num_workers=8)\n",
        "val_dl = torch.utils.data.DataLoader(valid_ds,\n",
        "                                       batch_size=batch_size,\n",
        "                                       shuffle=True,\n",
        "                                       num_workers=8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "HwkP4If7wx1u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a68f9d07-d3b0-4419-f8ea-5a652f7c72d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth\" to /root/.cache/torch/hub/checkpoints/wide_resnet50_2-95faca4d.pth\n",
            "100%|██████████| 132M/132M [00:01<00:00, 82.2MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (2): ReLU(inplace=True)\n",
              "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (5): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (6): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (7): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Load the pre-trained WideResNet model\n",
        "model = models.wide_resnet50_2(pretrained=True)\n",
        "\n",
        "# Remove the last layer from the model\n",
        "model = nn.Sequential(*list(model.children())[:-1])\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # Extract features from the model for the training set\n",
        "train_features = []\n",
        "train_labels = []\n",
        "train_dl = torch.utils.data.DataLoader(train_ds,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=8)\n",
        "\n",
        "for batch_idx, (data, target) in enumerate(train_dl):\n",
        "        data = data.to(device)\n",
        "        with torch.no_grad():\n",
        "            feature = model(data)\n",
        "        train_features.append(feature.cpu().numpy())\n",
        "        train_labels.append(target.numpy())\n",
        "\n",
        "train_features = np.concatenate(train_features, axis=0)\n",
        "train_labels = np.concatenate(train_labels, axis=0)"
      ],
      "metadata": {
        "id": "eh97h70yxCgT"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_features = []\n",
        "valid_labels = []\n",
        "valid_dl = torch.utils.data.DataLoader(valid_ds,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=8)\n",
        "\n",
        "for batch_idx, (data, target) in enumerate(valid_dl):\n",
        "        data = data.to(device)\n",
        "        with torch.no_grad():\n",
        "            feature = model(data)\n",
        "        valid_features.append(feature.cpu().numpy())\n",
        "        valid_labels.append(target.numpy())\n",
        "\n",
        "valid_features = np.concatenate(valid_features, axis=0)\n",
        "valid_labels = np.concatenate(valid_labels, axis=0)"
      ],
      "metadata": {
        "id": "dmEpfvUSxNX8"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "CPvRGTFxqUhO"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, 32)\n",
        "        self.fc3 = nn.Linear(32, output_dim)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.sigmoid(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.sigmoid(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.sigmoid(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def evaluate_model(model, features, labels, device):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    corrects = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    # Move the model and criterion to the GPU device\n",
        "    model.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(features), batch_size):\n",
        "            inputs = torch.from_numpy(features[i:i+batch_size]).float().to(device)\n",
        "            labels_inputs = labels[i:i+batch_size]\n",
        "            labels_inputs = torch.tensor(labels_inputs).to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels_inputs)\n",
        "\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            corrects += (preds == labels_inputs).sum().item()\n",
        "            total_samples += labels_inputs.size(0)\n",
        "\n",
        "    accuracy = 100.0 * corrects / total_samples\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "EmMONk-cM24S"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def compute_proj(W):\n",
        "  # Calculate W transpose\n",
        "  WT = W.t()\n",
        "\n",
        "  # Compute W * W.t()\n",
        "  WWt = torch.matmul(W, WT)\n",
        "\n",
        "  # Calculate the inverse of WWt\n",
        "  inverse_WWt = torch.inverse(WWt)\n",
        "\n",
        "  # Compute the expression W.t() * inverse(W * W.t()) * W\n",
        "  result = torch.matmul(torch.matmul(WT, inverse_WWt), W)\n",
        "\n",
        "\n",
        "  return result\n"
      ],
      "metadata": {
        "id": "0aCC3u5dOpEB"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hook(module, input, output):\n",
        "    setattr(module, 'input_tensor', input[0])\n",
        "    input_copy = input[0].clone()\n",
        "    output_copy = output.clone()"
      ],
      "metadata": {
        "id": "unHk972KfRR6"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def setatr(model):\n",
        "  for name, module in model.named_modules():\n",
        "      if isinstance(module, torch.nn.Linear):\n",
        "          module.register_forward_hook(hook)"
      ],
      "metadata": {
        "id": "GxdJxtgDfLtr"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the original list of classes\n",
        "classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "\n",
        "# Define a list to store the results\n",
        "Acc_without = []\n",
        "# Loop through the different combinations of class groupings\n",
        "for i in range(2, 10):\n",
        "    # Define the two arrays to hold the classes\n",
        "    known_classes = []\n",
        "    outlier_classes = []\n",
        "\n",
        "    # Randomly assign classes to the two arrays\n",
        "    for j in range(i):\n",
        "        known_classes.append(classes[j])\n",
        "    for j in range(i, 10):\n",
        "        outlier_classes.append(classes[j])\n",
        "\n",
        "    # Create a boolean mask to select the relevant samples\n",
        "    mask = np.isin(train_labels, known_classes)\n",
        "\n",
        "    # Select the relevant samples from the train_features and train_labels arrays\n",
        "    known_data = train_features[mask]\n",
        "    known_labels = train_labels[mask]\n",
        "\n",
        "    mask = np.isin(valid_labels, known_classes)\n",
        "\n",
        "    # Select the relevant samples from the valid_features and valid_labels arrays\n",
        "    known_data_valid = valid_features[mask]\n",
        "    known_labels_valid = valid_labels[mask]\n",
        "\n",
        "\n",
        "    # Train the network\n",
        "    input_dim = known_data.shape[1]\n",
        "    hidden_dim = 64\n",
        "    output_dim = len(known_classes)\n",
        "    lr = 1e-2\n",
        "    num_epochs = 10\n",
        "    batch_size = 128\n",
        "    net = Net(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "    # Move the model and criterion to the GPU device\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    net.to(device)\n",
        "    criterion = nn.CrossEntropyLoss().to(device)\n",
        "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
        "    losses = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Train the network\n",
        "        net.train()\n",
        "        num_batches = 0\n",
        "\n",
        "        for i in range(0, len(known_data), batch_size):\n",
        "            inputs = torch.from_numpy(known_data[i:i+batch_size]).float().to(device)\n",
        "            labels = torch.from_numpy(known_labels[i:i+batch_size]).long().to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            losses.append(loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            num_batches += 1\n",
        "\n",
        "    acc_without = evaluate_model(net, known_data_valid, known_labels_valid, device)\n",
        "    Acc_without.append(acc_without)\n",
        "    print(Acc_without)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBggRqPQUl6M",
        "outputId": "903a7604-7815-4c7a-9fe0-8f3772322420"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[97.6]\n",
            "[97.6, 95.46666666666667]\n",
            "[97.6, 95.46666666666667, 93.8]\n",
            "[97.6, 95.46666666666667, 93.8, 92.08]\n",
            "[97.6, 95.46666666666667, 93.8, 92.08, 88.86666666666666]\n",
            "[97.6, 95.46666666666667, 93.8, 92.08, 88.86666666666666, 86.34285714285714]\n",
            "[97.6, 95.46666666666667, 93.8, 92.08, 88.86666666666666, 86.34285714285714, 84.65]\n",
            "[97.6, 95.46666666666667, 93.8, 92.08, 88.86666666666666, 86.34285714285714, 84.65, 84.22222222222223]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define the original list of classes\n",
        "classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "\n",
        "# Define a list to store the results\n",
        "Acc_with = []\n",
        "# Loop through the different combinations of class groupings\n",
        "for i in range(2, 10):\n",
        "    # Define the two arrays to hold the classes\n",
        "    known_classes = []\n",
        "    outlier_classes = []\n",
        "\n",
        "    # Randomly assign classes to the two arrays\n",
        "    for j in range(i):\n",
        "        known_classes.append(classes[j])\n",
        "    for j in range(i, 10):\n",
        "        outlier_classes.append(classes[j])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Create a boolean mask to select the relevant samples\n",
        "    mask = np.isin(train_labels, known_classes)\n",
        "\n",
        "    # Select the relevant samples from the train_features and train_labels arrays\n",
        "\n",
        "    known_data = train_features[mask]\n",
        "    known_labels = train_labels[mask]\n",
        "\n",
        "\n",
        "    mask = np.isin(valid_labels, known_classes)\n",
        "\n",
        "    # Select the relevant samples from the valid_features and valid_labels arrays\n",
        "\n",
        "    known_data_valid = valid_features[mask]\n",
        "    known_labels_valid = valid_labels[mask]\n",
        "\n",
        "\n",
        "    # Train the network\n",
        "    input_dim = known_data.shape[1]\n",
        "    hidden_dim = 64\n",
        "    output_dim = len(known_classes)\n",
        "    lr = 1e-2\n",
        "    num_epochs = 10\n",
        "    batch_size = 128\n",
        "\n",
        "    net1 = Net(input_dim, hidden_dim, output_dim)\n",
        "    setatr(net1)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(net1.parameters(), lr=lr)\n",
        "    L = 0.1\n",
        "    losses = []\n",
        "\n",
        "    # Move the model and criterion to the GPU device\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    net1.to(device)\n",
        "    criterion.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      print(\"Epoch is {}\".format(epoch))\n",
        "      # Train the network\n",
        "      net1.train()\n",
        "      nusa_loss = 0.0\n",
        "      num_batches = 0\n",
        "\n",
        "      for i in range(0, len(known_data), batch_size):\n",
        "          inputs = torch.from_numpy(known_data[i:i+batch_size]).float().to(device)\n",
        "          labels = torch.from_numpy(known_labels[i:i+batch_size]).long().to(device)\n",
        "          optimizer.zero_grad()\n",
        "          outputs = net1(inputs)\n",
        "          arr=[]\n",
        "          # Compute nusa_loss for this batch\n",
        "          for name, module in net1.named_modules():\n",
        "              if isinstance(module, torch.nn.Linear):\n",
        "                  with torch.no_grad():\n",
        "                      xl = torch.tensor(module.input_tensor.tolist(), device=device)\n",
        "                      P = compute_proj(module.weight).to(device)\n",
        "                      projection = P.matmul(xl.t())\n",
        "                      norm_projection = torch.norm(projection)\n",
        "                      norm_xl = torch.norm(xl)\n",
        "                      nusa_loss = norm_projection / norm_xl\n",
        "                      arr.append(nusa_loss)\n",
        "\n",
        "          # Compute the total loss for this batch\n",
        "\n",
        "          loss = criterion(outputs, labels) + L * torch.tensor(arr).to(device).mean()\n",
        "\n",
        "          nusa_loss = 0.0\n",
        "          losses.append(loss)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          num_batches += 1\n",
        "    acc_with =  evaluate_model(net1,known_data_valid,known_labels_valid,device)\n",
        "    Acc_with.append(acc_with)\n",
        "    print(Acc_with)\n"
      ],
      "metadata": {
        "id": "x4QwtDnwgKOG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c623ca37-4724-495a-d3db-5b38d72c1068"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch is 0\n",
            "Epoch is 1\n",
            "Epoch is 2\n",
            "Epoch is 3\n",
            "Epoch is 4\n",
            "Epoch is 5\n",
            "Epoch is 6\n",
            "Epoch is 7\n",
            "Epoch is 8\n",
            "Epoch is 9\n",
            "[97.0]\n",
            "Epoch is 0\n",
            "Epoch is 1\n",
            "Epoch is 2\n",
            "Epoch is 3\n",
            "Epoch is 4\n",
            "Epoch is 5\n",
            "Epoch is 6\n",
            "Epoch is 7\n",
            "Epoch is 8\n",
            "Epoch is 9\n",
            "[97.0, 95.73333333333333]\n",
            "Epoch is 0\n",
            "Epoch is 1\n",
            "Epoch is 2\n",
            "Epoch is 3\n",
            "Epoch is 4\n",
            "Epoch is 5\n",
            "Epoch is 6\n",
            "Epoch is 7\n",
            "Epoch is 8\n",
            "Epoch is 9\n",
            "[97.0, 95.73333333333333, 93.4]\n",
            "Epoch is 0\n",
            "Epoch is 1\n",
            "Epoch is 2\n",
            "Epoch is 3\n",
            "Epoch is 4\n",
            "Epoch is 5\n",
            "Epoch is 6\n",
            "Epoch is 7\n",
            "Epoch is 8\n",
            "Epoch is 9\n",
            "[97.0, 95.73333333333333, 93.4, 91.68]\n",
            "Epoch is 0\n",
            "Epoch is 1\n",
            "Epoch is 2\n",
            "Epoch is 3\n",
            "Epoch is 4\n",
            "Epoch is 5\n",
            "Epoch is 6\n",
            "Epoch is 7\n",
            "Epoch is 8\n",
            "Epoch is 9\n",
            "[97.0, 95.73333333333333, 93.4, 91.68, 88.4]\n",
            "Epoch is 0\n",
            "Epoch is 1\n",
            "Epoch is 2\n",
            "Epoch is 3\n",
            "Epoch is 4\n",
            "Epoch is 5\n",
            "Epoch is 6\n",
            "Epoch is 7\n",
            "Epoch is 8\n",
            "Epoch is 9\n",
            "[97.0, 95.73333333333333, 93.4, 91.68, 88.4, 86.17142857142858]\n",
            "Epoch is 0\n",
            "Epoch is 1\n",
            "Epoch is 2\n",
            "Epoch is 3\n",
            "Epoch is 4\n",
            "Epoch is 5\n",
            "Epoch is 6\n",
            "Epoch is 7\n",
            "Epoch is 8\n",
            "Epoch is 9\n",
            "[97.0, 95.73333333333333, 93.4, 91.68, 88.4, 86.17142857142858, 85.25]\n",
            "Epoch is 0\n",
            "Epoch is 1\n",
            "Epoch is 2\n",
            "Epoch is 3\n",
            "Epoch is 4\n",
            "Epoch is 5\n",
            "Epoch is 6\n",
            "Epoch is 7\n",
            "Epoch is 8\n",
            "Epoch is 9\n",
            "[97.0, 95.73333333333333, 93.4, 91.68, 88.4, 86.17142857142858, 85.25, 84.44444444444444]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9Wd8nnWwemtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the number of known classes\n",
        "num_known_classes = np.arange(2, 10)\n",
        "\n",
        "# Define the width of each bar\n",
        "bar_width = 0.3\n",
        "\n",
        "# Plot the accuracy without Nusa\n",
        "plt.bar(num_known_classes + bar_width/2, Acc_without, width=bar_width, label='No Nusa')\n",
        "\n",
        "\n",
        "# Plot the accuracy with Nusa\n",
        "plt.bar(num_known_classes - bar_width/2, Acc_with, width=bar_width, label=' Nusa')\n",
        "\n",
        "\n",
        "\n",
        "# Add axis labels and title\n",
        "plt.xlabel('Number of known classes')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy comparison')\n",
        "\n",
        "# Add legend\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ImzbpFIx0HvU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "17c43878-6f4f-460a-ca5e-c9badc576212"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "known_classes = [0,1,2,3,4]\n",
        "outlier_classes = [5,6,7,8,9]\n",
        "\n",
        "\n",
        "\n",
        "mask = np.isin(train_labels, known_classes)\n",
        "print(mask)\n",
        "\n",
        "# Select the relevant samples from the train_features and train_labels arrays\n",
        "\n",
        "known_data = train_features[mask]\n",
        "known_labels = train_labels[mask]\n",
        "print(known_labels)\n",
        "\n",
        "\n",
        "mask = np.isin(valid_labels, known_classes)\n",
        "\n",
        "# Select the relevant samples from the valid_features and valid_labels arrays\n",
        "\n",
        "known_data_valid = valid_features[mask]\n",
        "known_labels_valid = valid_labels[mask]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "outlier_indicators = []\n",
        "outlier_class_labels = []\n",
        "\n"
      ],
      "metadata": {
        "id": "ICghuixt7rl1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6649cb74-04ea-4b6c-c622-7f480f458b0c"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[False False  True ...  True False False]\n",
            "[3 3 2 ... 2 2 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the network\n",
        "input_dim = known_data.shape[1]\n",
        "hidden_dim = 64\n",
        "output_dim = len(known_classes)\n",
        "lr = 1e-2\n",
        "batch_size=128\n",
        "num_epochs=100\n",
        "\n",
        "net1 = Net(input_dim, hidden_dim, output_dim)\n",
        "setatr(net1)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net1.parameters(), lr=lr)\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "losses = []\n",
        "nusa=[]\n",
        "\n"
      ],
      "metadata": {
        "id": "5ABmAL4V6Zun"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "net1.to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net1.parameters(), lr=lr)\n",
        "L = 0.1\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(\"Epoch is {}\".format(epoch))\n",
        "    # Train the network\n",
        "    net1.train()\n",
        "    nusa_loss = 0.0\n",
        "    num_batches = 0\n",
        "\n",
        "\n",
        "    for i in range(0, len(known_data), batch_size):\n",
        "        inputs = torch.from_numpy(known_data[i:i+batch_size]).float().to(device)\n",
        "        labels = torch.from_numpy(known_labels[i:i+batch_size]).long().to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net1(inputs)\n",
        "        arr=[]\n",
        "        # Compute nusa_loss for this batch\n",
        "        for name, module in net1.named_modules():\n",
        "            if isinstance(module, torch.nn.Linear):\n",
        "                with torch.no_grad():\n",
        "                    xl = module.input_tensor.to(device)\n",
        "                    P = compute_proj(module.weight.to(device))\n",
        "                    projection = P.matmul(xl.t())\n",
        "                    norm_projection = torch.norm(projection)\n",
        "                    norm_xl = torch.norm(xl)\n",
        "                    nusa_loss = norm_projection / norm_xl\n",
        "                    arr.append(nusa_loss)\n",
        "\n",
        "        # Compute the total loss for this batch\n",
        "        loss = criterion(outputs, labels) + L * torch.tensor(arr).to(device).mean()\n",
        "        arr=[]\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        num_batches += 1\n",
        ""
      ],
      "metadata": {
        "id": "ehVMFpCC_Zab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42d2af9a-86bc-48e6-93fb-d12b92f2876b"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch is 0\n",
            "Epoch is 1\n",
            "Epoch is 2\n",
            "Epoch is 3\n",
            "Epoch is 4\n",
            "Epoch is 5\n",
            "Epoch is 6\n",
            "Epoch is 7\n",
            "Epoch is 8\n",
            "Epoch is 9\n",
            "Epoch is 10\n",
            "Epoch is 11\n",
            "Epoch is 12\n",
            "Epoch is 13\n",
            "Epoch is 14\n",
            "Epoch is 15\n",
            "Epoch is 16\n",
            "Epoch is 17\n",
            "Epoch is 18\n",
            "Epoch is 19\n",
            "Epoch is 20\n",
            "Epoch is 21\n",
            "Epoch is 22\n",
            "Epoch is 23\n",
            "Epoch is 24\n",
            "Epoch is 25\n",
            "Epoch is 26\n",
            "Epoch is 27\n",
            "Epoch is 28\n",
            "Epoch is 29\n",
            "Epoch is 30\n",
            "Epoch is 31\n",
            "Epoch is 32\n",
            "Epoch is 33\n",
            "Epoch is 34\n",
            "Epoch is 35\n",
            "Epoch is 36\n",
            "Epoch is 37\n",
            "Epoch is 38\n",
            "Epoch is 39\n",
            "Epoch is 40\n",
            "Epoch is 41\n",
            "Epoch is 42\n",
            "Epoch is 43\n",
            "Epoch is 44\n",
            "Epoch is 45\n",
            "Epoch is 46\n",
            "Epoch is 47\n",
            "Epoch is 48\n",
            "Epoch is 49\n",
            "Epoch is 50\n",
            "Epoch is 51\n",
            "Epoch is 52\n",
            "Epoch is 53\n",
            "Epoch is 54\n",
            "Epoch is 55\n",
            "Epoch is 56\n",
            "Epoch is 57\n",
            "Epoch is 58\n",
            "Epoch is 59\n",
            "Epoch is 60\n",
            "Epoch is 61\n",
            "Epoch is 62\n",
            "Epoch is 63\n",
            "Epoch is 64\n",
            "Epoch is 65\n",
            "Epoch is 66\n",
            "Epoch is 67\n",
            "Epoch is 68\n",
            "Epoch is 69\n",
            "Epoch is 70\n",
            "Epoch is 71\n",
            "Epoch is 72\n",
            "Epoch is 73\n",
            "Epoch is 74\n",
            "Epoch is 75\n",
            "Epoch is 76\n",
            "Epoch is 77\n",
            "Epoch is 78\n",
            "Epoch is 79\n",
            "Epoch is 80\n",
            "Epoch is 81\n",
            "Epoch is 82\n",
            "Epoch is 83\n",
            "Epoch is 84\n",
            "Epoch is 85\n",
            "Epoch is 86\n",
            "Epoch is 87\n",
            "Epoch is 88\n",
            "Epoch is 89\n",
            "Epoch is 90\n",
            "Epoch is 91\n",
            "Epoch is 92\n",
            "Epoch is 93\n",
            "Epoch is 94\n",
            "Epoch is 95\n",
            "Epoch is 96\n",
            "Epoch is 97\n",
            "Epoch is 98\n",
            "Epoch is 99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(net1,known_data_valid,known_labels_valid,device)"
      ],
      "metadata": {
        "id": "fEbmneT-jXgo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "326cc94c-9731-4d7a-a007-0dfba359dc9b"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "92.4"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "array=[]\n",
        "array1=[]\n",
        "threshold=.8\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Check if GPU is available\n",
        "\n",
        "with torch.no_grad():\n",
        "  for i in range(len(valid_features)):\n",
        "    nusa = 0.0\n",
        "    sample = valid_features[i]\n",
        "    label = valid_labels[i]\n",
        "\n",
        "    # Forward pass through the network\n",
        "    inputs = torch.from_numpy(sample).unsqueeze(0).float().to(device)  # Move data to GPU\n",
        "    net1.to(device)  # Move model to GPU\n",
        "    outputs = net1(inputs)\n",
        "\n",
        "    # Compute NuSA for the sample\n",
        "    arr=[]\n",
        "    for index,(name, module) in enumerate(net1.named_modules()):\n",
        "\n",
        "                if isinstance(module, torch.nn.Linear):\n",
        "                  with torch.no_grad():\n",
        "                    xl = torch.tensor(module.input_tensor.tolist()).to(device)  # Move data to GPU\n",
        "                    P = compute_proj(module.weight)\n",
        "                    P=torch.matmul(P.t(),P)\n",
        "                    projection = torch.matmul(P,xl.t())\n",
        "                    norm_projection = torch.norm(projection)\n",
        "\n",
        "                    norm_xl = torch.norm(xl)\n",
        "                    nusa = norm_projection/norm_xl\n",
        "                    arr.append(nusa)\n",
        "    arr=[]\n",
        "    if( label  in known_classes):\n",
        "      array.append(nusa)\n",
        "    else:\n",
        "      array1.append(nusa)\n",
        "\n",
        "    # Check if the sample is an outlier based on NuSA and threshold\n",
        "    if nusa > threshold:\n",
        "        _, predicted_label = torch.max(outputs, 1)\n",
        "        outlier_indicators.append(0)  # Non-outlier\n",
        "        outlier_class_labels.append(predicted_label.item())\n",
        "    else:\n",
        "        outlier_indicators.append(1)  # Outlier\n",
        "        outlier_class_labels.append(None)\n"
      ],
      "metadata": {
        "id": "Yu0wF8Km_6Rp"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"NuSa for non-outliers\", torch.tensor(array).to(device).mean().item())\n",
        "print(\"NuSa for outliers\", torch.tensor(array1).to(device).mean().item())"
      ],
      "metadata": {
        "id": "_NS47ekQ2Gl6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "253cb724-8cbe-4cb4-88b3-e64c94f73b38"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NuSa for non-outliers 0.8002946376800537\n",
            "NuSa for outliers 0.7743954062461853\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}